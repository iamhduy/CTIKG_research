# CTIKG_research
replication of ctikg

To set up local LLMs:
https://huggingface.co/01-ai/Yi-1.5-6B-Chat

- Choose Use this model -> vLLms"
- Install and activate conda environment first
- pip install vllm
- vllm serve "01-ai/Yi-1.5-6B-Chat"
- run python file in another terminal
